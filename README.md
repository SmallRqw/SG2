# SGRD and SG2
With the rapid development in the field of artificial intelligence, isolated object-level perception tasks have achieved tremendous success. However, in the field of object group understanding, existing remote sensing scene graph generation (SGG) methods, a structured description of objects and their inter relationships, tend to focus on comprehensive scenes with numerous elements and complex relationships, which may obscure the characterization of high-value relationships. Consequently, in specific scenes, the concise and efficient description of spatial-temporal relationships between high-value objects (such as vehicles and ships) presents a challenge.
    Simultaneously, the complexity of spatial relationships within the remote sensing object group necessitates the use of global context to aid in predicting these relationships, while fine-grained local context is essential for accurate relationship prediction. To address this, we propose a Ship Group Relationship Description method (SGRD) based on remote sensing SGG with a global and local context fusion network, called GLFN. The proposed network integrates global feature fusion through a Transformer-based self-attention mechanism and enhances local feature fusion using a graph convolutional network focused on object-specific graph structures. Additionally, we introduce a new dataset featuring Ship Group Scene Graphs, named SG2, derived and refined from the HRSC2016 dataset. Experimental results demonstrate that GLFN achieves competitive performance on SG2 in specific scenes compared to classical and recent SGG methods, offering potential for relationship-guided change detection and situational awareness.
